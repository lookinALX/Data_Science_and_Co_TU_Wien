Dataset;Number of citations (Google Scholar);Number of Papers (Papers with code since 2020);Number of Evaluations (Papers with code API);Music/Speech/Sounds;Link;Paper Link;Model in Paper (Paper Link if Link Model Paper == null);Model in Paper Input Data;Score or best score in Paper;Metrics in Paper;Year;Author;Original Usecase;Accessable;Downloadable;Download Comment;Category Source;Size Number of Samples;Size (Hours);Contents based on;Source;Language;Number of Benchmarks (Audio Classification or Recognition Papers with Code different models);Best Scoure;Best Model related to scoure;Best Model Input Data;Metrics related to scoure;Link Model Paper;Comment
AudioSet;3950,00;591,00;70,00;Sounds;https://research.google.com/audioset/;https://ieeexplore.ieee.org/document/7952261;CNN;Spectrogram;31,400;mAP (mean Average Precision);2017;Google;Audio classification;yes;Hard;"Registration required; Videos";YouTube audio clips;2100000;5800;short video clips;Youtube;English;53,00;55,80;OmniVec2;Spectrogram;mAP (mean Average Precision);https://paperswithcode.com/paper/omnivec2-a-novel-transformer-based-network;n/a
AudioCaps;570,00;223,00;98,00;Sounds;https://audiocaps.github.io/;https://aclanthology.org/N19-1011/;VGGish-LSTM ;Not Relevant;"19,3;50,9";"METEOR;CIDEr";2019;n/a;Audio captioning;yes;Easy;Direct download;YouTube audio clips;50535;135;audio clips;AudioSet subset ;English;n/a;n/a;n/a;n/a;n/a;n/a;n/a
AVSpeech;959,00;36,00;0,00;Speech;https://looking-to-listen.github.io/;https://arxiv.org/abs/1804.03619;n/a;Not Relevant;n/a;n/a;2018;Google;Automatic speech recognition;yes;Medium;Videos;YouTube videos;470000;4700;short video clips;"Youtube; TED Talks";English;n/a;n/a;n/a;n/a;n/a;n/a;n/a
UrbanSound8K;1653,00;100,00;4,00;Sounds;https://urbansounddataset.weebly.com/urbansound8k.html;https://www.justinsalamon.com/uploads/4/3/9/4/4394963/salamon_urbansound_acmmm14.pdf;SVM;Mel-Frequency Cepstral Coefficients (MFCC);70,000;Accuracy;2014;Freesound.org;Audio classification;yes;Easy;Direct download;Environment recordings;8732;8,75;audio clips;Freesound.org;n/a;4,00;98,05;FACE;Mel-Frequency Cepstral Coefficients (MFCC);Accuracy;https://arxiv.org/pdf/2303.03666v1;n/a
ESC-50;1872,00;302,00;540,00;Sounds;https://github.com/karolpiczak/ESC-50;https://dl.acm.org/doi/10.1145/2733373.2806390;n/a;n/a;n/a;n/a;2015;n/a;Audio classification;yes;Easy;Direct download;Environment recordings;2000;2,78;audio clips;Freesound.org;n/a;50,00;99,10;OmniVec2;Spectrogram;Accuracy;https://paperswithcode.com/paper/omnivec2-a-novel-transformer-based-network;n/a
LibriSpeech;7494,00;1922,00;2,00;Speech;https://www.openslr.org/12;https://ieeexplore.ieee.org/document/7178964;DNN 960h  ;Not Relevant;5,510;WER (World Error Rate);2015;LibriVox;Automatic speech recognition;yes;Easy;Direct download;Audiobooks;n/a;1000;audibooks;LibriVox.com;English;115,00;0,99;United-MedASR;Not Relevant;WER (World Error Rate);https://arxiv.org/pdf/2412.00055v1;n/a
VGG-Sound;618,00;179,00;16,00;Sounds;https://www.robots.ox.ac.uk/~vgg/data/vggsound/;https://arxiv.org/abs/2004.14368;ResNet50;Spectrogram;53,200;mAP (mean Average Precision);2020;n/a;Audio classification;no;n/a;Download link not available;YouTube videos;200000;550;short video clips;Youtube;n/a;29,00;69,80;Mirasol3B;Spectrogram;Top1 Accuracy;https://arxiv.org/pdf/2311.05698v3;n/a
FSD50K;524,00;139,00;10,00;Sounds;https://zenodo.org/records/4060432;https://dl.acm.org/doi/10.1109/TASLP.2021.3133208;n/a;n/a;n/a;n/a;2020;n/a;Audio classification;yes;Easy;Direct download;User-contributed sounds;51197;80,4;short video clips;"Freesound.org; AudioSet";English;9,00;69,70;ONE-PEACE;Raw Audio;mAP (mean Average Precision);https://arxiv.org/pdf/2305.11172v1;n/a
Common Voice;1787,00;363,00;6,00;Speech;"https://commonvoice.mozilla.org/en/datasets; https://huggingface.co/datasets/common_voice";https://arxiv.org/abs/1912.06670;"A six-layer unidirectional CTC
model, with one LSTM layer.";Not Relevant;43,600;Character Error Rate;2019;Mozilla;Automatic speech recognition;yes;Easy;Direct download;User-contributed sounds;n/a;7335;audio clips;Crowdsourcing;Multilingual;14,00;23437,00;"wav2vec 2.0 XLS-R 1B + TEVR
(5-gram)";Not Relevant;WER (World Error Rate);https://arxiv.org/pdf/2206.12693v1;German was taken
GTZAN;1420,00;12,00;16,00;Music;https://www.tensorflow.org/datasets/catalog/gtzan;https://ieeexplore.ieee.org/document/1021072;GMM (Genres);Mel-Frequency Cepstral Coefficients (MFCC);60,000;Accuracy;2001;n/a;Music classification;yes;Medium;Not direct;Music recordings;1000;8,33;music tracks;Personal recordings;n/a;6,00;87,00;wav2vec2-base-finetuned-gtzan;n/a;Accuracy;https://huggingface.co/juangtzi/wav2vec2-base-finetuned-gtzan;http://marsyas.info/index.html
VoxCeleb1;793,00;490,00;41,00;Speech;https://www.robots.ox.ac.uk/~vgg/data/voxceleb/;https://www.sciencedirect.com/science/article/pii/S0885230819302712;"ResNet-50 (3);";Spectrogram;0,524;Detection Cost Function (DCF);2018;n/a;Audio classification;yes;Medium;Videos;YouTube videos;n/a;2400;short video clips;Youtube;Multilingual;n/a;n/a;n/a;n/a;n/a;https://www.isca-archive.org/interspeech_2018/chung18b_interspeech.pdf;English was taken
ICBHI Respiratory Sound Database;313,00;12,00;22,00;Sounds;https://bhichallenge.med.auth.gr/ICBHI_2017_Challenge;;n/a;n/a;n/a;n/a;2016; University;Medical audio analysis;yes;Easy;Direct download;Medical recordings;6898;5,5;audio clips;Recoding;n/a;21,00;63,54;BTS;Not Relevant;ICBHI Score;https://arxiv.org/pdf/2406.06786v2;n/a
SHD (Spiking Heidelberg Digits);209,00;16,00;11,00;Speech;https://zenkelab.org/resources/spiking-heidelberg-datasets-shd/;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9311226;CNN;Spectrogram;92,400;Accuracy;2022;Zenke Lab;Audio classification;yes;Easy;Direct download;Speech recordings;10420;4,5;audio clips;Recoding;English;11,00;95,90;Event-SSM;Raw Audio;Accuracy;https://arxiv.org/pdf/2404.18508v3;n/a
Speech Commands;1882,00;336,00;16,00;Speech;https://huggingface.co/datasets/google/speech_commands;https://arxiv.org/pdf/1804.03209;CNN;Spectrogram;88,000;Top One Accuracy;2018;Google;Audio classification;yes;Medium;Not direct;User-contributed sounds;100503;28;audio clips;n/a;English;7,00;98,30;EAT;Spectrogram;Accuracy;https://arxiv.org/pdf/2401.03497v1;n/a
TAU2020;132,00;0,00;0,00;Sounds;https://zenodo.org/records/3670167;https://arxiv.org/abs/2006.01919;CNN (SELD);Spectrogram;n/a;n/a;2020;n/a;Audio classification;yes;Easy;Direct download;Mixed sources;n/a;64;audio clips;Public area recordings;n/a;n/a;n/a;n/a;n/a;n/a;n/a;n/a
TUT Sound Events 2017;603,00;7,00;0,00;Sounds;https://zenodo.org/records/400515;https://homepages.tuni.fi/tuomas.virtanen/papers/dcase-2017-challenge-paper.pdf;n/a;n/a;61,000;Accuracy;2017;n/a;Audio classification;yes;Medium;Not direct;Environment recordings;100;4;audio clips;Public area recordings;n/a;1,00;64,90;Qwen-Audio;Spectrogram;Accuracy;https://arxiv.org/pdf/2311.07919v2;n/a
MACS (Multi-Annotator Captioned Soundscapes);40,00;9,00;0,00;Sounds;https://zenodo.org/records/5114771;https://arxiv.org/abs/2104.04214;n/a;n/a;n/a;n/a;2021;n/a;Audio captioning;yes;Medium;Not direct;Environment recordings;n/a;11;audio clips;TAU subset;n/a;n/a;n/a;n/a;n/a;n/a;n/a;n/a
MagnaTagATune;236,00;41,00;3,00;Music;https://mirg.city.ac.uk/codeapps/the-magnatagatune-dataset;https://ismir2009.ismir.net/proceedings/OS5-5.pdf;algorithm bot;Mel-Frequency Cepstral Coefficients (MFCC);70,000;Accuracy;2009;n/a;Music classification;yes;Easy;Direct download;Music recordings;25863;136,8;audio clips;Crowdsourcing;n/a;3,00;45,50;EAsTAl;Spectrogram;mAP (mean Average Precision);https://arxiv.org/pdf/2306.17424v1;n/a
Kinetics-700;179,00;89,00;38,00;Sounds;https://github.com/cvdfoundation/kinetics-dataset;https://arxiv.org/abs/2010.10864;ResNet50;Spectrogram;80,000;Accuracy;2020;Google;Audio classification;yes;Easy;Direct download;YouTube videos;n/a;1805;short video clips;Youtube;n/a;36,00;85,90;InternVideo2-6B;;Top1 Accuracy;https://arxiv.org/pdf/2403.15377v4;Only Audio Task
MusicNet;250,00;27,00;6,00;Music;https://zenodo.org/records/5120004#.YXDPwKBlBpQ;https://arxiv.org/pdf/1611.09827;CNN, 64 stride;Not Relevant;67,800;Average Precision;2016;n/a;Music transcription;yes;Easy;Direct download;Music recordings;330;34;music tracks;Public archive;n/a;n/a;n/a;n/a;Not Relevant;n/a;n/a;n/a
EmoDB Dataset (Berlin Database of Emotional Speech);3072,00;6,00;0,00;Speech;https://audeering.github.io/datasets/datasets/emodb.html;https://www.researchgate.net/publication/221491017_A_database_of_German_emotional_speech;n/a;n/a;n/a;n/a;2005;"T-Systems; University";Audio classification;yes;Easy;Direct download;Speech recordings;n/a;0,41;audio clips;Recoding;German;1,00;90,20;VQ-MAE-S-12 (Frame) ;Spectrogram;"	Accuracy";https://arxiv.org/pdf/2304.11117v1;n/a
SEP-28k;118,00;18,00;0,00;Speech;https://github.com/apple/ml-stuttering-events-dataset/;https://arxiv.org/pdf/2102.12394;ConvLSTM;Spectrogram;66,800;Accuracy;2021;Apple;Audio classification;yes;Medium;Not direct;Speech recordings;n/a;23;audio clips;Podcasts;English;n/a;n/a;n/a;n/a;n/a;n/a;n/a
EPIC-SOUNDS (EPIC-KITCHENS-100);47,00;148,00;2,00;Sounds;https://epic-kitchens.github.io/epic-sounds/;https://arxiv.org/pdf/2302.00646;MTCN?;Raw Audio;30,800;mAP (mean Average Precision);2023;University;Audio classification;yes;Medium;Videos;Video recordings;n/a;100;audio clips;Recoding;n/a;4,00;46,00;Audiovisual Masked Autoencoder (Audiovisual, Single);Spectrogram;"	Accuracy";https://arxiv.org/pdf/2212.05922v3;Action classification based on audio
MINDS-14;29,00;0,00;0,00;Speech;https://huggingface.co/datasets/PolyAI/minds14/tree/main/data;https://arxiv.org/pdf/2104.08524;Google ASR;Raw Audio;93,300;Accuracy;2021;PolyAI;Audio classification;yes;Easy;Direct download;Speech recordings;n/a;27;audio clips;Crowdsourcing;Multilingual;n/a;58,00;DP-DyLoRA;Spectrogram;"	Accuracy";https://arxiv.org/pdf/2405.06368;SPEECH RECOGNITION. paper found on Scholar
BGG (PUBG Gun Sound Dataset);8,00;1,00;0,00;Sounds;https://github.com/junwoopark92/PUBG-Gun-Sound-Dataset;https://ieeexplore.ieee.org/abstract/document/9893670;CNN-Transformer;Spectrogram;95,290;Accuracy (Firearm classification);2022;University;Audio classification;no;n/a;Download link not available;Game audio;n/a;5;audio clips;Recoding;n/a;n/a;n/a;n/a;n/a;n/a;n/a;n/a
ReefSet;2,00;1,00;0,00;Sounds;https://zenodo.org/records/11071202;https://arxiv.org/abs/2404.16436;n/a;n/a;95,000;Mean AUC-ROC;2024;University;Bioacoustics analysis;yes;Easy;Direct download;Environment recordings;57084;30;audio clips;Enviroment recording;n/a;n/a;n/a;n/a;n/a;n/a;n/a;n/a
Multimodal PISA (Multimodal Piano Skills Assessment);35,00;1,00;3,00;Music;https://github.com/ParitoshParmar/Piano-Skills-Assessment;https://ieeexplore.ieee.org/document/9733638;MMDL;Spectrogram;74,600;Accuracy;2021;University;Music classification;yes;Medium;File format;Music recordings;n/a;n/a;short video clips;Recoding;n/a;1,00;64,50;CNN;Spectrogram;"	Accuracy";https://arxiv.org/pdf/2212.05922v3;n/a
WavText5k;62,00;0,00;0,00;Sounds;https://github.com/microsoft/WavText5K;https://arxiv.org/abs/2209.14275;n/a;n/a;n/a;n/a;2022;Microsoft;Automatic speech recognition;yes;Medium;File format;Speech recordings;4525;25,48;audio clips;"cross-collection; BigSoundBank 2; SoundBible";n/a;n/a;n/a;n/a;n/a;n/a;n/a;n/a
OpenMIC-2018;111,00;7,00;4,00;Music;https://zenodo.org/records/1432913;https://archives.ismir.net/ismir2018/paper/000248.pdf;Random Forest baseline;Spectrogram;82,000;Accuracy;2018;Spotify;Music classification;yes;Easy;Direct download;Music recordings;n/a;55,5;music tracks;Free Music Archive (FMA);n/a;4,00;85,50;DyMN-L;Spectrogram;mAP (mean Average Precision);https://arxiv.org/pdf/2310.15648v1;Instrument Recognition
MELD;1329,00;223,00;68,00;Speech;https://affective-meld.github.io/;https://arxiv.org/pdf/1810.02508;DialogueRNN (text + audio);Spectrogram;60,250;F-Score;2018;n/a;Speech emotion recognition;yes;Easy;Direct download;Video recordings;n/a;18;short video clips;TV show;English;66,00;68,70;ELR-GNN;Mel-Frequency Cepstral Coefficients (MFCC);"	Accuracy";https://arxiv.org/pdf/2407.00119v2;Emotion Recognition in Conversation
MedleyDB;96,00;16,00;0,00;Music;https://zenodo.org/records/1344103;https://arxiv.org/pdf/1605.06644;CNN;Spectrogram;74,000;Accuracy;2018;Spotify;Music classification;yes;Easy;Direct download;Music recordings;n/a;18;audio clips;"cross-collection; MedleyDB";n/a;n/a;n/a;n/a;n/a;n/a;n/a;n/a
FLEURS;280,00;100,00;3,00;Speech;https://www.tensorflow.org/datasets/catalog/xtreme_s;https://arxiv.org/pdf/2205.12446;mSLAM (0.6B) ;Text;73,300;Accuracy;2022;"Meta; Google; University";Audio classification;yes;Medium;Not direct;Speech recordings;n/a;1400;audio clips;Wikipedia;English;15,00;0,34;United-MedASR;Text;WER (World Error Rate);https://arxiv.org/pdf/2412.00055v1;SPEECH RECOGNITION
Audio Dialogues;7,00;0,00;0,00;"Music; Sounds";https://audiodialogues.github.io/;https://arxiv.org/pdf/2404.07616;Audio Flamingo;Not Relevant;1,672;CIDEr;2024;NVIDIA;Automatic speech recognition;no;n/a;Pay to download;Speech recordings;n/a;n/a;audio clips;Artificially generated (text promts);English;n/a;n/a;n/a;n/a;n/a;n/a;n/a
DEEP-VOICE: DeepFake Voice Recognition (Jordan Bird);25,00;1,00;0,00;Speech;https://www.kaggle.com/datasets/birdy654/deep-voice-deepfake-voice-recognition;https://arxiv.org/pdf/2308.12734;Gradient Descent ;Spectrogram;0,139;F1;2023;University;Audio classification;no;n/a;Download link not available;AI-generated synthetic speech;n/a;1;audio clips;n/a;English;1,00;99,30;XGBoost;Spectrogram;Accuracy (10-fold);https://arxiv.org/pdf/2308.12734v1;n/a
RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song);2154,00;25,00;0,00;Speech;https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio;https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0196391;n/a;n/a;n/a;n/a;2018;University;Audio classification;yes;Easy;Direct download;Singing recordings;1440;1,5;short video clips;Recoding;English;2,00;75,40;ASM-RH-A;Spectrogram;Top1 Accuracy;https://arxiv.org/pdf/2402.18007v2;Audio Classification
SoundDesc;207,00;6,00;0,00;Sounds;https://github.com/akoepke/audio-retrieval-benchmark;https://arxiv.org/abs/2112.09418;n/a;n/a;n/a;n/a;2022;n/a;Audio classification;yes;Hard;"Not direct; File format";Environment recordings;n/a;1060;audio clips;BBC Sound Effects;n/a;n/a;n/a;n/a;n/a;n/a;n/a;Speech separation
Switchboard-1 Corpus;0;4,00;0,00;Speech;https://catalog.ldc.upenn.edu/LDC97S62;n/a;n/a;n/a;n/a;n/a;1997;LDC;Automatic Speech Recognition;no;n/a;Pay to download;Speech recordings;n/a;200;audio clips;Recoding;English;10,00;82,90;Bi-RNN + Self-Attention + Context;;"	Accuracy";https://arxiv.org/pdf/1904.02594v2;Dialogue Act Classification
MUSDB18;324,00;75,00;29,00;Music;https://zenodo.org/records/1117372;https://zenodo.org/records/1117372;n/a;n/a;n/a;n/a;2017;n/a;Music source separation;yes;Easy;Direct download;Music recordings;150;9;music tracks;Free music libraries;n/a;n/a;n/a;n/a;n/a;n/a;n/a;"Speech separation; https://sigsep.github.io/datasets/musdb.html"
DiCOVA;115,00;19,00;3,00;Sounds;https://dicova2021.github.io/;https://arxiv.org/abs/2103.09148;RF (Sound Cough);Mel-Frequency Cepstral Coefficients (MFCC);70,690;Area under the curve (AUC);2021;n/a;Audio classification;no;n/a;Download link not available;Medical recordings;1040;1,36;audio clips;Crowdsourcing;n/a;n/a;n/a;n/a;n/a;n/a;n/a;Dataset is not accesable
IEMOCAP;4124,00;558,00;81,00;Speech;https://sail.usc.edu/iemocap/;https://link.springer.com/article/10.1007/s10579-008-9076-6;n/a;n/a;n/a;n/a;2008;University;Speech emotion recognition;no;n/a;Download link not available;Speech recordings;n/a;5;audio clips;Recoding;English;59,00;73,95;SDT;Mel-Frequency Cepstral Coefficients (MFCC);Accuracy;https://arxiv.org/pdf/2310.20494v1;Emotion Recognition
WSJ0-2mix;1812,00;114,00;33,00;Speech;https://catalog.ldc.upenn.edu/LDC93S6A;https://aclanthology.org/H92-1073/;n/a;n/a;n/a;n/a;1992;LDC;Automatic speech recognition;no;n/a;Pay to download;Speech recordings;n/a;400;audio clips;Recoding;English;n/a;n/a;n/a;n/a;n/a;n/a;Speech separation
DEMAND;672,00;0,00;0,00;Sounds;https://zenodo.org/records/1227121;https://inria.hal.science/hal-00796707/document;n/a;n/a;n/a;n/a;2013;University;Automatic speech recognition;yes;Easy;Direct download;Environment recordings;n/a;20;audio clips;Recoding;n/a;n/a;n/a;n/a;n/a;n/a;n/a;n/a
Coswara Dataset;362,00;0,00;0,00;Sounds;https://github.com/iiscleap/Coswara-Data;https://arxiv.org/abs/2005.10548;n/a;n/a;n/a;n/a;2020;n/a;Audio classification;yes;Medium;File format;Medical recordings;n/a;n/a;audio clips;Crowdsourcing;n/a;n/a;99,00;CNN (leave-one-out);;Accuracy;https://dergipark.org.tr/en/download/article-file/3033184;n/a
WavCaps;156,00;31,00;0,00;Sounds;https://github.com/XinhaoMei/WavCaps;https://arxiv.org/pdf/2303.17395v2;n/a;n/a;n/a;n/a;2024;University;Audio captioning;yes;Hard;"File format; Videos";Environment recordings;n/a;1120;audio clips;Freesound.org;n/a;n/a;n/a;n/a;n/a;n/a;n/a;n/a
TED-LIUM;372,00;43,00;2,00;Speech;https://www.openslr.org/51/;https://arxiv.org/pdf/1805.04699;n/a;n/a;n/a;n/a;2019;University;Automatic speech recognition;yes;Easy;Direct download;Speech recordings;n/a;452;short video clips;TED Talks;English;6,00;0,29;"United-MedASR
(764M)";Spectrogram;WER (World Error Rate);https://arxiv.org/pdf/2412.00055v1;n/a
COUGHVID;334,00;27,00;0,00;Sounds;https://c4science.ch/diffusion/10770/;https://www.nature.com/articles/s41597-021-00937-4;eXtreme Gradient Boosting (XGB)1;n/a;86,700;Accuracy;2021;n/a;Audio classification;yes;Easy;Direct download;Medical recordings;n/a;35;audio clips;Crowdsourcing;n/a;n/a;0,70;OPERA-CT;Spectrogram;MRR;https://arxiv.org/pdf/2406.16148v3;n/a
Wham!;394,00;91,00;0,00;Speech;http://wham.whisper.ai/;https://www.arxiv.org/abs/1907.01160;n/a;n/a;n/a;n/a;2019;WhisperAI;Automatic speech recognition;yes;Easy;Direct download;Environment recordings;n/a;45;audio clips;Recoding;Multilingual;n/a;n/a;n/a;n/a;n/a;n/a;Speech separation
Cat Meow;0,00;0,00;0,00;Sounds;https://www.kaggle.com/datasets/andrewmvd/cat-meow-classification;https://d1wqtxts1xzle7.cloudfront.net/94765084/Ludovico2021_Chapter_CatMeowsAPublicly-AvailableDat-libre.pdf?1669278110=&response-content-disposition=inline%3B+filename%3DCatMeows_A_Publicly_Available_Dataset_of.pdf&Expires=1734885889&Signature=gIFKEtCtihOopajb0Hdx0F2Hx4Z-gZKXJ1xuU-~mT3Lfmm2BQsTUW2qf1BR~OVgo7ScrWIibg0mR3IE~5Alpz5Tictf0CM~mVHdtzeYVkNyHoq82PB5B96puKLTuFhNPC5T8P-g7jyCzzMPzYzu0Xp98zUEgr~QWW31Fkva4kQO9SfOeys6QCqAxNp~EULwXQme3H5SQQVcOqCyX0Vvp706h1149oHgbQ-qr95APjzaQeHjUUYtKihYMrXJdQoXlWDujK0Geordg7jvl8uDklUHnrxt5hLQLWLJzz00lJbxYL5WBwc-w9bQaer4mVBNNiBebn0EeOFnqpxroQu9HrA__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA;RandomForestClassifier;n/a;0,730;F1;2021;University;Audio classification;yes;Easy;Direct download;Animal recordings;n/a;0,3;audio clips;Recoding;n/a;n/a;n/a;n/a;n/a;n/a;https://www.kaggle.com/code/kanyaratp29/csc287-cat-sound-classification#Evaluation;n/a
CochlScene;22,00;4,00;2,00;Sounds;https://zenodo.org/records/7080122;https://arxiv.org/abs/2211.02289;n/a;n/a;n/a;n/a;2022;n/a;Audio classification;yes;Easy;Direct download;Environment recordings;n/a;211,5;audio clips;Crowdsourcing;n/a;2,00;83,00;NVIDIA Audio Flamingo;n/a;Accuracy;https://arxiv.org/pdf/2402.01831v3;n/a
SONYC-UST-V2;44,00;4,00;0,00;Sounds;https://zenodo.org/records/3966543;https://arxiv.org/abs/2009.05188;baseline classifier with STC;n/a;0,830;"label-weighted
label-ranking average precision (LWLRAP) - on coarse level";2020;University;Audio classification;yes;Medium;File format;Environment recordings;n/a;51,4;audio clips;Recoding;n/a;n/a;n/a;n/a;n/a;n/a;n/a;n/a
Free Spoken Digit Dataset (FSDD);50,00;3,00;0,00;Speech;https://github.com/Jakobovski/free-spoken-digit-dataset?tab=readme-ov-file;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10206077;Deep Convolution Neural Network (DCNN);Spectrogram;97,6;Accuracy;2018;MNIST;Audio classification;yes;Easy;Direct download;Speech recordings;n/a;0,83;audio clips;Crowdsourcing;English;n/a;n/a;n/a;n/a;n/a;n/a;n/a
AudioMNIST;43,00;3,00;0,00;Speech;https://github.com/soerenab/AudioMNIST;https://arxiv.org/pdf/1807.03418;AlexNet (spectrogram);Spectrogram;95,820;Accuracy;2018;MNIST;Audio classification;yes;Easy;Direct download;Speech recordings;n/a;8,33;audio clips;Recoding;English;n/a;n/a;n/a;n/a;n/a;n/a;n/a
AFRODIGITS;1,00;0,00;0,00;Speech;n/a;https://arxiv.org/pdf/2303.12582;Wav2Vec2.0;Raw Audio;97,100;Accuracy;2023;n/a;Audio classification;no;n/a;Download link not available;Speech recordings;n/a;n/a;audio clips;Crowdsourcing;English;n/a;n/a;n/a;n/a;n/a;n/a;n/a
SpokeN-100;1,00;0,00;0,00;Speech;https://zenodo.org/records/10810044;https://arxiv.org/html/2403.09753v1;EfficientNet-B0 CNN;Spectrogram;84,800;Accuracy;2024;University;Audio classification;yes;Easy;Direct download;AI-generated synthetic speech;n/a;3,56;audio clips;Artificially generated (text promts);Multilingual;n/a;n/a;n/a;n/a;n/a;n/a;n/a
Clotho;;;;;;;;;;;;;;;;;;5929;37,05;audio clips;;;;;;;;;
MACS;;;;;;;;;;;;;;;;;;3930;11,88;audio clips;;;;;;;;;
SoundDescs;;;;;;;;;;;;;;;;;;32979;1060,40;audio clips;;;;;;;;;
