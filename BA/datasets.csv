Dataset;Number of citations (Google Scholar);Number of Papers (Papers with code since 2020);Number of Evaluations (Papers with code API);Music/Speech/Sounds;Link;Paper Link;Model in Paper (Paper Link if Link Model Paper == null);Score or best score in Paper;Metrics in Paper;Year;Author;Original Use Case;Accessable;Downloadable;Download Comment;Category Source;Size (Hours);Contents based on;Source;Language;Number of Benchmarks (Audio Classification or Recognition Papers with Code different models);Best Scoure;Best Model related to scoure;Metrics related to scoure;Link Model Paper;Comment
AudioSet;3950,00;591,00;70,00;Sounds;https://research.google.com/audioset/;https://ieeexplore.ieee.org/document/7952261;CNN;31,400;mAP (mean Average Precision);2017;Google;Audio classification;yes;Hard;"Registration required; Videos";Videos;58000;short video clips;Youtube;English;53,00;55,80;OmniVec2;mAP (mean Average Precision);https://paperswithcode.com/paper/omnivec2-a-novel-transformer-based-network;n/a
AudioCaps;570,00;223,00;98,00;Sounds;https://audiocaps.github.io/;https://aclanthology.org/N19-1011/;VGGish-LSTM ;"19,3;50,9";"METEOR;CIDEr";2019;n/a;Audio captioning;yes;Easy;Direct download;Videos;108,60;audio clips;AudioSet subset ;English;n/a;n/a;n/a;n/a;n/a;n/a
AVSpeech;959,00;36,00;0,00;Speech;https://looking-to-listen.github.io/;https://arxiv.org/abs/1804.03619;n/a;n/a;n/a;2018;Google;Audio-visual speech enhancement;yes;Medium;Videos;Videos;4700;short video clips;"Youtube; TED Talks";English;n/a;n/a;n/a;n/a;n/a;n/a
UrbanSound8K;1653,00;100,00;4,00;Sounds;https://urbansounddataset.weebly.com/urbansound8k.html;https://www.justinsalamon.com/uploads/4/3/9/4/4394963/salamon_urbansound_acmmm14.pdf;SVM;70,000;Accuracy;2014;Freesound.org;Audio classification;yes;Easy;Direct download;Sounds;27607;audio clips;Freesound.org;n/a;4,00;98,05;FACE;Accuracy;https://arxiv.org/pdf/2303.03666v1;n/a
ESC-50;1872,00;302,00;540,00;Sounds;https://github.com/karolpiczak/ESC-50;https://dl.acm.org/doi/10.1145/2733373.2806390;n/a;n/a;n/a;2015;n/a;Audio classification;yes;Easy;Direct download;Sounds;28157;audio clips;Freesound.org;n/a;50,00;99,10;OmniVec2;Accuracy;https://paperswithcode.com/paper/omnivec2-a-novel-transformer-based-network;n/a
LibriSpeech;7494,00;1922,00;2,00;Speech;https://www.openslr.org/12;https://ieeexplore.ieee.org/document/7178964;DNN 960h  ;5,510;WER (World Error Rate);2015;LibriVox;Automatic speech recognition;yes;Easy;Direct download;Speech;1000;audibooks;LibriVox.com;English;115,00;0,99;United-MedASR;WER (World Error Rate);https://arxiv.org/pdf/2412.00055v1;n/a
VGG-Sound;618,00;179,00;16,00;Sounds;https://www.robots.ox.ac.uk/~vgg/data/vggsound/;https://arxiv.org/abs/2004.14368;ResNet50;53,200;mAP (mean Average Precision);2020;n/a;Audio classification;no;n/a;Download link not available;Videos;550;short video clips;Youtube;n/a;29,00;69,80;Mirasol3B;Top1 Accuracy;https://arxiv.org/pdf/2311.05698v3;n/a
FSD50K;524,00;139,00;10,00;Sounds;https://zenodo.org/records/4060432;https://dl.acm.org/doi/10.1109/TASLP.2021.3133208;n/a;n/a;n/a;2020;n/a;Audio classification;yes;Easy;Direct download;Videos;145;short video clips;"Freesound.org ;AudioSet";English;9,00;69,70;ONE-PEACE;mAP (mean Average Precision);https://arxiv.org/pdf/2305.11172v1;n/a
Common Voice;1787,00;363,00;6,00;Speech;"https://commonvoice.mozilla.org/en/datasets; https://huggingface.co/datasets/common_voice";https://arxiv.org/abs/1912.06670;"A six-layer unidirectional CTC
model, with one LSTM layer.";43,600;Character Error Rate;2019;Mozilla;Automatic speech recognition;yes;Easy;Direct download;Speech;45;audio clips;Crowdsourcing;Multilingual;14,00;23437,00;"wav2vec 2.0 XLS-R 1B + TEVR
(5-gram)";WER (World Error Rate);https://arxiv.org/pdf/2206.12693v1;German was taken
GTZAN;1420,00;12,00;16,00;Music;https://www.tensorflow.org/datasets/catalog/gtzan;https://ieeexplore.ieee.org/document/1021072;GMM (Genres);60,000;Accuracy;2001;n/a;Music classification;yes;Medium;Not direct;Music;45724;music tracks;Multiple;n/a;6,00;87,00;wav2vec2-base-finetuned-gtzan;Accuracy;https://huggingface.co/juangtzi/wav2vec2-base-finetuned-gtzan;http://marsyas.info/index.html
VoxCeleb1;793,00;490,00;41,00;Speech;https://www.robots.ox.ac.uk/~vgg/data/voxceleb/;https://www.sciencedirect.com/science/article/pii/S0885230819302712;"ResNet-50 (3);";0,524;Detection Cost Function (DCF);2018;n/a;Speaker recognition;yes;Medium;Videos;Speech;2400;short video clips;Youtube;Multilingual;n/a;n/a;n/a;n/a;https://www.isca-archive.org/interspeech_2018/chung18b_interspeech.pdf;English was taken
ICBHI Respiratory Sound Database;313,00;12,00;22,00;Sounds;https://bhichallenge.med.auth.gr/ICBHI_2017_Challenge;;n/a;n/a;n/a;2016; University;Medical audio analysis;yes;Easy;Direct download;Sounds;45782;audio clips;Recoding;n/a;21,00;63,54;BTS;ICBHI Score;https://arxiv.org/pdf/2406.06786v2;n/a
SHD (Spiking Heidelberg Digits);209,00;16,00;11,00;Speech;https://zenkelab.org/resources/spiking-heidelberg-datasets-shd/;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9311226;CNN;92,400;Accuracy;2022;Zenke Lab;Neuromorphic speech processing;yes;Easy;Direct download;Speech;n/a;audio clips;Recoding;English;11,00;95,90;Event-SSM;Accuracy;https://arxiv.org/pdf/2404.18508v3;n/a
Speech Commands;1882,00;336,00;16,00;Speech;https://huggingface.co/datasets/google/speech_commands;https://arxiv.org/pdf/1804.03209;CNN;88,000;Top One Accuracy;2018;Google;Keyword spotting;yes;Medium;Not direct;Videos;616;audio clips;n/a;English;7,00;98,30;EAT;Accuracy;https://arxiv.org/pdf/2401.03497v1;n/a
TAU2020;132,00;0,00;0,00;Sounds;https://zenodo.org/records/3670167;https://arxiv.org/abs/2006.01919;CNN (SELD);n/a;n/a;2020;n/a;Audio classification;yes;Easy;Direct download;Sounds;64;audio clips;Public area recordings;n/a;n/a;n/a;n/a;n/a;n/a;n/a
TUT Sound Events 2017;603,00;7,00;0,00;Sounds;https://zenodo.org/records/400515;https://homepages.tuni.fi/tuomas.virtanen/papers/dcase-2017-challenge-paper.pdf;n/a;61,000;Accuracy;2017;n/a;Audio classification;yes;Medium;Not direct;Sounds;24;audio clips;Public area recordings;n/a;1,00;64,90;Qwen-Audio;Accuracy;https://arxiv.org/pdf/2311.07919v2;n/a
MACS (Multi-Annotator Captioned Soundscapes);40,00;9,00;0,00;Sounds;https://zenodo.org/records/5114771;https://arxiv.org/abs/2104.04214;n/a;n/a;n/a;2021;n/a;Audio captioning;yes;Medium;Not direct;Sounds;11;audio clips;TAU subset;n/a;n/a;n/a;n/a;n/a;n/a;n/a
MagnaTagATune;236,00;41,00;3,00;Music;https://mirg.city.ac.uk/codeapps/the-magnatagatune-dataset;https://ismir2009.ismir.net/proceedings/OS5-5.pdf;algorithm bot;70,000;Accuracy;2009;n/a;Music classification;yes;Easy;Direct download;Music;136,80;audio clips;Crowdsourcing;n/a;3,00;45,50;EAsTAl;mAP (mean Average Precision);https://arxiv.org/pdf/2306.17424v1;n/a
Kinetics-700;179,00;89,00;38,00;Sounds;https://github.com/cvdfoundation/kinetics-dataset;https://arxiv.org/abs/2010.10864;I3D;80,000;Accuracy;2020;Google;Audio classification;yes;Easy;Direct download;Sounds;1805;short video clips;Youtube;n/a;36,00;85,90;InternVideo2-6B;Top1 Accuracy;https://arxiv.org/pdf/2403.15377v4;Only Audio Task
MusicNet;250,00;27,00;6,00;Music;https://zenodo.org/records/5120004#.YXDPwKBlBpQ;https://arxiv.org/pdf/1611.09827;CNN, 64 stride;67,800;Average Precision;2016;n/a;Music transcription;yes;Easy;Direct download;Music;34;music tracks;Public archive;n/a;n/a;n/a;n/a;n/a;n/a;n/a
EmoDB Dataset (Berlin Database of Emotional Speech);3072,00;6,00;0,00;Speech;https://audeering.github.io/datasets/datasets/emodb.html;https://www.researchgate.net/publication/221491017_A_database_of_German_emotional_speech;not relevant;not relevant;not relevant;2005;"T-Systems; University";Speech emotion recognition;yes;Easy;Direct download;Speech;0,41;audio clips;Recoding;German;1,00;90,20;VQ-MAE-S-12 (Frame) ;"	Accuracy";https://arxiv.org/pdf/2304.11117v1;n/a
SEP-28k;118,00;18,00;0,00;Speech;https://github.com/apple/ml-stuttering-events-dataset/;https://arxiv.org/pdf/2102.12394;ConvLSTM;66,800;Accuracy;2021;Apple;Audio classification;yes;Medium;Not direct;Speech;23;audio clips;Podcasts;English;n/a;n/a;n/a;n/a;n/a;n/a
EPIC-SOUNDS (EPIC-KITCHENS-100);47,00;148,00;2,00;Sounds;https://epic-kitchens.github.io/epic-sounds/;https://arxiv.org/pdf/2302.00646;MTCN?;30,800;mAP (mean Average Precision);2023;University;Audio classification;yes;Medium;Videos;Sounds;100;audio clips;Recoding;n/a;4,00;46,00;Audiovisual Masked Autoencoder (Audiovisual, Single);"	Accuracy";https://arxiv.org/pdf/2212.05922v3;Action classification based on audio
MINDS-14;29,00;0,00;0,00;Speech;https://huggingface.co/datasets/PolyAI/minds14/tree/main/data;https://arxiv.org/pdf/2104.08524;Google ASR;93,300;Accuracy;2021;PolyAI;Speaker recognition;yes;Easy;Direct download;Speech;27;audio clips;Crowdsourcing;Multilingual;n/a;58,00;DP-DyLoRA;"	Accuracy";https://arxiv.org/pdf/2405.06368;SPEECH RECOGNITION. paper found on Scholar
BGG (PUBG Gun Sound Dataset);8,00;1,00;0,00;Sounds;https://github.com/junwoopark92/PUBG-Gun-Sound-Dataset;https://ieeexplore.ieee.org/abstract/document/9893670;CNN-Transformer;95,290;Accuracy (Firearm classification);2022;University;Audio classification;no;n/a;Download link not available;Sounds;5;audio clips;Recoding;n/a;n/a;n/a;n/a;n/a;n/a;n/a
ReefSet;2,00;1,00;0,00;Sounds;https://zenodo.org/records/11071202;https://arxiv.org/abs/2404.16436;n/a;95,000;Mean AUC-ROC;2024;University;Bioacoustics analysis;yes;Easy;Direct download;Sounds;45898;audio clips;Enviroment recording;n/a;n/a;n/a;n/a;n/a;n/a;n/a
Multimodal PISA (Multimodal Piano Skills Assessment);35,00;1,00;3,00;Music;https://github.com/ParitoshParmar/Piano-Skills-Assessment;https://ieeexplore.ieee.org/document/9733638;MMDL;74,600;Accuracy;2021;University;Music classification;yes;Medium;File format;Music;n/a;short video clips;Recoding;n/a;1,00;64,50;CNN;"	Accuracy";https://arxiv.org/pdf/2212.05922v3;n/a
WavText5k;62,00;0,00;0,00;Sounds;https://github.com/microsoft/WavText5K;https://arxiv.org/abs/2209.14275;n/a;n/a;n/a;2022;Microsoft;Automatic speech recognition;yes;Medium;File format;Sounds;45802;audio clips;"cross-collection; BigSoundBank 2 + SoundBible";n/a;n/a;n/a;n/a;n/a;n/a;n/a
OpenMIC-2018;111,00;7,00;4,00;Music;https://zenodo.org/records/1432913;https://archives.ismir.net/ismir2018/paper/000248.pdf;Random Forest baseline;82,000;Accuracy;2018;Spotify;Music classification;yes;Easy;Direct download;Music;55,50;music tracks;Free Music Archive (FMA);n/a;4,00;85,50;DyMN-L;mAP (mean Average Precision);https://arxiv.org/pdf/2310.15648v1;Instrument Recognition
MELD;1329,00;223,00;68,00;Speech;https://affective-meld.github.io/;https://arxiv.org/pdf/1810.02508;DialogueRNN (text + audio);60,250;F-Score;2018;n/a;Speech emotion recognition;yes;Easy;Direct download;Videos;18;short video clips;TV show;English;66,00;68,70;ELR-GNN;"	Accuracy";https://arxiv.org/pdf/2407.00119v2;Emotion Recognition in Conversation
MedleyDB;96,00;16,00;0,00;Music;https://zenodo.org/records/1344103;https://arxiv.org/pdf/1605.06644;CNN;74,000;Accuracy;2018;Spotify;Music classification;yes;Easy;Direct download;Music;18;audio clips;"cross-collection; MedleyDB + solosDB";n/a;n/a;n/a;n/a;n/a;n/a;n/a
FLEURS;280,00;100,00;3,00;Speech;https://www.tensorflow.org/datasets/catalog/xtreme_s;https://arxiv.org/pdf/2205.12446;mSLAM (0.6B) ;73,300;Accuracy;2022;"Meta; Google; University";Automatic speech recognition;yes;Medium;Not direct;Text;1400;audio clips;Wikipedia;English;15,00;0,34;United-MedASR;WER (World Error Rate);https://arxiv.org/pdf/2412.00055v1;SPEECH RECOGNITION
Audio Dialogues;7,00;0,00;0,00;"Music; Sound";https://audiodialogues.github.io/;https://arxiv.org/pdf/2404.07616;Audio Flamingo;1,672;CIDEr;2024;NVIDIA;Automatic speech recognition;no;n/a;Pay to download;Text;n/a;audio clips;ChatGPT text promts;English;n/a;n/a;n/a;n/a;n/a;n/a
DEEP-VOICE: DeepFake Voice Recognition (Jordan Bird);25,00;1,00;0,00;Speech;https://www.kaggle.com/datasets/birdy654/deep-voice-deepfake-voice-recognition;https://arxiv.org/pdf/2308.12734;Gradient Descent ;0,139;F1;2023;University;Deepfake detection;no;n/a;Download link not available;Speech;1;audio clips;n/a;English;1,00;99,30;XGBoost;Accuracy (10-fold);https://arxiv.org/pdf/2308.12734v1;n/a
RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song);2154,00;25,00;0,00;Speech;https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio;https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0196391;n/a;n/a;n/a;2018;University;Speech emotion recognition;yes;Easy;Direct download;Speech;45797;short video clips;Recoding;English;2,00;75,40;ASM-RH-A;Top1 Accuracy;https://arxiv.org/pdf/2402.18007v2;Audio Classification
SoundDesc;207,00;6,00;0,00;Sounds;https://github.com/akoepke/audio-retrieval-benchmark;https://arxiv.org/abs/2112.09418;n/a;n/a;n/a;2022;n/a;Audio classification;yes;Hard;"Not direct; File format";Sounds;1060;audio clips;BBC Sound Effects;n/a;n/a;n/a;n/a;n/a;n/a;Speech separation
Switchboard-1 Corpus;0;4,00;0,00;Speech;https://catalog.ldc.upenn.edu/LDC97S62;n/a;n/a;n/a;n/a;1997;LDC;Automatic Speech Recognition;no;n/a;Pay to download;Speech;200;audio clips;Recoding;English;10,00;82,90;Bi-RNN + Self-Attention + Context;"	Accuracy";https://arxiv.org/pdf/1904.02594v2;Dialogue Act Classification
MUSDB18;324,00;75,00;29,00;Music;https://zenodo.org/records/1117372;https://zenodo.org/records/1117372;n/a;n/a;n/a;2017;n/a;Music source separation;yes;Easy;Direct download;Music;45784;music tracks;Free music libraries;n/a;n/a;n/a;n/a;n/a;n/a;"Speech separation; https://sigsep.github.io/datasets/musdb.html"
DiCOVA;115,00;19,00;3,00;Sounds;https://dicova2021.github.io/;https://arxiv.org/abs/2103.09148;RF (Sound Cough);70,690;Area under the curve (AUC);2021;n/a;Audio classification;no;n/a;Download link not available;Sounds;13150;audio clips;Crowdsourcing;n/a;n/a;n/a;n/a;n/a;n/a;Dataset is not accesable
IEMOCAP;4124,00;558,00;81,00;Speech;https://sail.usc.edu/iemocap/;https://link.springer.com/article/10.1007/s10579-008-9076-6;n/a;n/a;n/a;2008;University;Speech emotion recognition;no;n/a;Download link not available;Speech;5;audio clips;Recoding;English;59,00;73,95;SDT;Accuracy;https://arxiv.org/pdf/2310.20494v1;Emotion Recognition
WSJ0-2mix;1812,00;114,00;33,00;Speech;https://catalog.ldc.upenn.edu/LDC93S6A;https://aclanthology.org/H92-1073/;n/a;n/a;n/a;1992;LDC;Automatic speech recognition;no;n/a;Pay to download;Speech;400;audio clips;Recoding;English;n/a;n/a;n/a;n/a;n/a;Speech separation
DEMAND;672,00;0,00;0,00;Sounds;https://zenodo.org/records/1227121;https://inria.hal.science/hal-00796707/document;n/a;n/a;n/a;2013;University;Speech enhancement;yes;Easy;Direct download;Sounds;45658;audio clips;Recoding;n/a;n/a;n/a;n/a;n/a;n/a;n/a
Coswara Dataset;362,00;0,00;0,00;Sounds;https://github.com/iiscleap/Coswara-Data;https://arxiv.org/abs/2005.10548;n/a;n/a;n/a;2020;n/a;Audio classification;yes;Medium;File format;Sounds;n/a;audio clips;Crowdsourcing;n/a;n/a;99,00;CNN (leave-one-out);Accuracy;https://dergipark.org.tr/en/download/article-file/3033184;n/a
WavCaps;156,00;31,00;0,00;Sounds;https://github.com/XinhaoMei/WavCaps;https://arxiv.org/pdf/2303.17395v2;n/a;n/a;n/a;2024;University;Audio captioning;yes;Hard;"File format; Videos";Sounds;1120;audio clips;Freesound.org;n/a;n/a;n/a;n/a;n/a;n/a;n/a
TED-LIUM;372,00;43,00;2,00;Speech;https://www.openslr.org/51/;https://arxiv.org/pdf/1805.04699;n/a;n/a;n/a;2019;University;Automatic speech recognition;yes;Easy;Direct download;Speech;452;short video clips;TED talks;English;6,00;0,29;"United-MedASR
(764M)";WER (World Error Rate);https://arxiv.org/pdf/2412.00055v1;n/a
COUGHVID;334,00;27,00;0,00;Sounds;https://c4science.ch/diffusion/10770/;https://www.nature.com/articles/s41597-021-00937-4;eXtreme Gradient Boosting (XGB)1;86,700;Accuracy;2021;n/a;Audio classification;yes;Easy;Direct download;Sounds;35;audio clips;Crowdsourcing;n/a;n/a;0,70;OPERA-CT;MRR;https://arxiv.org/pdf/2406.16148v3;n/a
Wham!;394,00;91,00;0,00;Speech;http://wham.whisper.ai/;https://www.arxiv.org/abs/1907.01160;n/a;n/a;n/a;2019;WhisperAI;Speech separation;yes;Easy;Direct download;Speech;45;audio clips;Recoding;Multilingual;n/a;n/a;n/a;n/a;n/a;Speech separation
Cat Meow;0,00;0,00;0,00;Sounds;https://www.kaggle.com/datasets/andrewmvd/cat-meow-classification;https://d1wqtxts1xzle7.cloudfront.net/94765084/Ludovico2021_Chapter_CatMeowsAPublicly-AvailableDat-libre.pdf?1669278110=&response-content-disposition=inline%3B+filename%3DCatMeows_A_Publicly_Available_Dataset_of.pdf&Expires=1734885889&Signature=gIFKEtCtihOopajb0Hdx0F2Hx4Z-gZKXJ1xuU-~mT3Lfmm2BQsTUW2qf1BR~OVgo7ScrWIibg0mR3IE~5Alpz5Tictf0CM~mVHdtzeYVkNyHoq82PB5B96puKLTuFhNPC5T8P-g7jyCzzMPzYzu0Xp98zUEgr~QWW31Fkva4kQO9SfOeys6QCqAxNp~EULwXQme3H5SQQVcOqCyX0Vvp706h1149oHgbQ-qr95APjzaQeHjUUYtKihYMrXJdQoXlWDujK0Geordg7jvl8uDklUHnrxt5hLQLWLJzz00lJbxYL5WBwc-w9bQaer4mVBNNiBebn0EeOFnqpxroQu9HrA__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA;RandomForestClassifier;0,730;F1;2021;University;Audio classification;yes;Easy;Direct download;Sounds;0,30;audio clips;Recoding;n/a;n/a;n/a;n/a;n/a;https://www.kaggle.com/code/kanyaratp29/csc287-cat-sound-classification#Evaluation;n/a
CochlScene;22,00;4,00;2,00;Sounds;https://zenodo.org/records/7080122;https://arxiv.org/abs/2211.02289;n/a;n/a;n/a;2022;n/a;Audio classification;yes;Easy;Direct download;Sounds;211,50;audio clips;Crowdsourcing;n/a;2,00;83,00;NVIDIA Audio Flamingo;Accuracy;https://arxiv.org/pdf/2402.01831v3;n/a
SONYC-UST-V2;44,00;4,00;0,00;Sounds;https://zenodo.org/records/3966543;https://arxiv.org/abs/2009.05188;baseline classifier with STC;0,830;"label-weighted
label-ranking average precision (LWLRAP) - on coarse level";2020;University;Audio classification;yes;Medium;File format;Sounds;51,40;audio clips;Recoding;n/a;n/a;n/a;n/a;n/a;n/a;n/a
