Echoing to file start
Save config dict to file
Set seed to 1234
Start loading data
End loading data
Generate Datalaoder
Generate Datalaoder end
Start training
step=0 loss=4.2018 running loss=4.1977 , time=3.6058 expected time=317.3118
Epoch 1, train_loss=3.9083, train_acc=0.0214 val_loss=4.1170,  val_acc=0.0266
step=0 loss=3.6473 running loss=3.6433 , time=1.2321 expected time=108.4248
Epoch 2, train_loss=3.6728, train_acc=0.0507 val_loss=3.8119,  val_acc=0.0266
step=0 loss=3.6030 running loss=3.5980 , time=1.2307 expected time=108.2977
Epoch 3, train_loss=3.5218, train_acc=0.0621 val_loss=3.6388,  val_acc=0.0598
step=0 loss=3.3418 running loss=3.3356 , time=1.2395 expected time=109.0731
Epoch 4, train_loss=3.3485, train_acc=0.0814 val_loss=3.4339,  val_acc=0.0797
step=0 loss=3.4384 running loss=3.4309 , time=1.2299 expected time=108.2334
Epoch 5, train_loss=3.2926, train_acc=0.1071 val_loss=3.4035,  val_acc=0.0930
step=0 loss=3.4859 running loss=3.4774 , time=1.2449 expected time=109.5479
Epoch 6, train_loss=3.1999, train_acc=0.1136 val_loss=3.3075,  val_acc=0.1296
step=0 loss=2.9443 running loss=2.9347 , time=1.2315 expected time=108.3736
Epoch 7, train_loss=3.0571, train_acc=0.1343 val_loss=3.0208,  val_acc=0.1495
step=0 loss=3.3474 running loss=3.3366 , time=1.2479 expected time=109.8191
Epoch 8, train_loss=2.9616, train_acc=0.1786 val_loss=2.9169,  val_acc=0.2093
step=0 loss=3.0703 running loss=3.0586 , time=1.2354 expected time=108.7178
Epoch 9, train_loss=2.8962, train_acc=0.1729 val_loss=3.0443,  val_acc=0.1628
step=0 loss=2.2914 running loss=2.2788 , time=1.2528 expected time=110.2474
Epoch 10, train_loss=2.8095, train_acc=0.1950 val_loss=3.0228,  val_acc=0.1728
step=0 loss=2.9526 running loss=2.9394 , time=1.2502 expected time=110.0184
Epoch 11, train_loss=2.7977, train_acc=0.1921 val_loss=2.7131,  val_acc=0.2193
step=0 loss=3.1599 running loss=3.1464 , time=1.2617 expected time=111.0254
Epoch 12, train_loss=2.7234, train_acc=0.2243 val_loss=2.7468,  val_acc=0.2159
step=0 loss=2.7179 running loss=2.7038 , time=1.2399 expected time=109.1114
Epoch 13, train_loss=2.6641, train_acc=0.2321 val_loss=2.7762,  val_acc=0.2159
step=0 loss=2.6100 running loss=2.5954 , time=1.2466 expected time=109.7012
Epoch 14, train_loss=2.6068, train_acc=0.2343 val_loss=2.8812,  val_acc=0.2027
step=0 loss=2.0249 running loss=2.0099 , time=1.2528 expected time=110.2478
Epoch 15, train_loss=2.5891, train_acc=0.2521 val_loss=2.6825,  val_acc=0.2724
step=0 loss=2.2501 running loss=2.2348 , time=1.2455 expected time=109.6002
Epoch 16, train_loss=2.5318, train_acc=0.2529 val_loss=2.4845,  val_acc=0.3123
step=0 loss=2.4806 running loss=2.4649 , time=1.2409 expected time=109.1987
Epoch 17, train_loss=2.4527, train_acc=0.2864 val_loss=2.6894,  val_acc=0.2591
step=0 loss=2.2410 running loss=2.2249 , time=1.2400 expected time=109.1201
Epoch 18, train_loss=2.4517, train_acc=0.2871 val_loss=3.0576,  val_acc=0.1827
step=0 loss=2.1514 running loss=2.1352 , time=1.2548 expected time=110.4249
Epoch 19, train_loss=2.4282, train_acc=0.2979 val_loss=2.5324,  val_acc=0.2857
step=0 loss=2.3409 running loss=2.3246 , time=1.2515 expected time=110.1298
Epoch 20, train_loss=2.3245, train_acc=0.3050 val_loss=2.3739,  val_acc=0.3090
step=0 loss=2.0413 running loss=2.0244 , time=1.2429 expected time=109.3785
Epoch 21, train_loss=2.2871, train_acc=0.3250 val_loss=2.5906,  val_acc=0.2857
step=0 loss=2.2274 running loss=2.2101 , time=1.6339 expected time=143.7849
Epoch 22, train_loss=2.2236, train_acc=0.3464 val_loss=2.4117,  val_acc=0.3056
step=0 loss=2.0663 running loss=2.0487 , time=1.2412 expected time=109.2217
Epoch 23, train_loss=2.2187, train_acc=0.3550 val_loss=2.4791,  val_acc=0.2924
step=0 loss=2.7996 running loss=2.7818 , time=1.2438 expected time=109.4546
Epoch 24, train_loss=2.1663, train_acc=0.3543 val_loss=2.5191,  val_acc=0.3322
step=0 loss=1.8255 running loss=1.8074 , time=1.2427 expected time=109.3596
Epoch 25, train_loss=2.1538, train_acc=0.3621 val_loss=2.3461,  val_acc=0.3056
step=0 loss=2.0791 running loss=2.0608 , time=1.2255 expected time=107.8415
Epoch 26, train_loss=2.0812, train_acc=0.3621 val_loss=2.3393,  val_acc=0.3588
step=0 loss=2.3749 running loss=2.3564 , time=1.2431 expected time=109.3962
Epoch 27, train_loss=2.0689, train_acc=0.3993 val_loss=2.4063,  val_acc=0.3090
step=0 loss=2.4731 running loss=2.4544 , time=1.2350 expected time=108.6781
Epoch 28, train_loss=2.0256, train_acc=0.3914 val_loss=2.2540,  val_acc=0.3721
step=0 loss=1.6378 running loss=1.6191 , time=1.2463 expected time=109.6740
Epoch 29, train_loss=1.9549, train_acc=0.4164 val_loss=2.2984,  val_acc=0.3588
step=0 loss=1.6451 running loss=1.6261 , time=1.2447 expected time=109.5339
Epoch 30, train_loss=1.9743, train_acc=0.4150 val_loss=2.2971,  val_acc=0.3156
step=0 loss=1.3202 running loss=1.3011 , time=1.2383 expected time=108.9739
Epoch 31, train_loss=1.9070, train_acc=0.4379 val_loss=2.4156,  val_acc=0.3156
step=0 loss=1.9588 running loss=1.9396 , time=1.2598 expected time=110.8636
Epoch 32, train_loss=1.9036, train_acc=0.4279 val_loss=2.2390,  val_acc=0.3854
step=0 loss=1.7750 running loss=1.7557 , time=1.2435 expected time=109.4297
Epoch 33, train_loss=1.8457, train_acc=0.4436 val_loss=2.2491,  val_acc=0.3721
step=0 loss=1.6738 running loss=1.6544 , time=1.2233 expected time=107.6479
Epoch 34, train_loss=1.8071, train_acc=0.4657 val_loss=2.2735,  val_acc=0.3522
step=0 loss=1.4078 running loss=1.3883 , time=1.2462 expected time=109.6629
Epoch 35, train_loss=1.7722, train_acc=0.4636 val_loss=2.3330,  val_acc=0.3522
step=0 loss=1.9150 running loss=1.8953 , time=1.2415 expected time=109.2535
Epoch 36, train_loss=1.7689, train_acc=0.4729 val_loss=2.1930,  val_acc=0.4053
step=0 loss=1.4977 running loss=1.4779 , time=1.2475 expected time=109.7832
Epoch 37, train_loss=1.7427, train_acc=0.4686 val_loss=2.1559,  val_acc=0.4053
step=0 loss=1.7128 running loss=1.6930 , time=1.2354 expected time=108.7167
Epoch 38, train_loss=1.7296, train_acc=0.4829 val_loss=2.2262,  val_acc=0.4153
step=0 loss=0.9216 running loss=0.9018 , time=1.2486 expected time=109.8762
Epoch 39, train_loss=1.6421, train_acc=0.5136 val_loss=2.1466,  val_acc=0.4120
step=0 loss=1.8621 running loss=1.8422 , time=1.2449 expected time=109.5526
Epoch 40, train_loss=1.6395, train_acc=0.4943 val_loss=2.2002,  val_acc=0.4020
step=0 loss=1.5829 running loss=1.5629 , time=1.2447 expected time=109.5308
Epoch 41, train_loss=1.6459, train_acc=0.5029 val_loss=2.2471,  val_acc=0.3920
step=0 loss=1.0103 running loss=0.9904 , time=1.2484 expected time=109.8622
Epoch 42, train_loss=1.6042, train_acc=0.5114 val_loss=2.1665,  val_acc=0.4020
step=0 loss=1.3105 running loss=1.2905 , time=1.2725 expected time=111.9833
Epoch 43, train_loss=1.6281, train_acc=0.5171 val_loss=2.1654,  val_acc=0.4252
step=0 loss=1.1299 running loss=1.1099 , time=1.2299 expected time=108.2315
Epoch 44, train_loss=1.5436, train_acc=0.5364 val_loss=2.1216,  val_acc=0.4219
step=0 loss=1.8553 running loss=1.8353 , time=1.2488 expected time=109.8924
Epoch 45, train_loss=1.5802, train_acc=0.5236 val_loss=2.1424,  val_acc=0.4385
step=0 loss=1.7592 running loss=1.7392 , time=1.2431 expected time=109.3945
Epoch 46, train_loss=1.5203, train_acc=0.5371 val_loss=2.1180,  val_acc=0.4385
step=0 loss=2.2116 running loss=2.1915 , time=1.2447 expected time=109.5325
Epoch 47, train_loss=1.5107, train_acc=0.5436 val_loss=2.0988,  val_acc=0.4319
step=0 loss=1.0609 running loss=1.0408 , time=1.2478 expected time=109.8075
Epoch 48, train_loss=1.4906, train_acc=0.5486 val_loss=2.0556,  val_acc=0.4551
step=0 loss=1.7100 running loss=1.6898 , time=1.2648 expected time=111.3000
Epoch 49, train_loss=1.4615, train_acc=0.5479 val_loss=2.1316,  val_acc=0.4385
step=0 loss=1.4581 running loss=1.4380 , time=1.2426 expected time=109.3464
Epoch 50, train_loss=1.4739, train_acc=0.5493 val_loss=2.0964,  val_acc=0.4485
step=0 loss=1.2641 running loss=1.2440 , time=1.2486 expected time=109.8777
Epoch 51, train_loss=1.4798, train_acc=0.5543 val_loss=2.1127,  val_acc=0.4585
step=0 loss=1.4630 running loss=1.4428 , time=1.2408 expected time=109.1880
Epoch 52, train_loss=1.4044, train_acc=0.5657 val_loss=2.0913,  val_acc=0.4551
step=0 loss=1.1847 running loss=1.1645 , time=1.2489 expected time=109.9037
Epoch 53, train_loss=1.3810, train_acc=0.5764 val_loss=2.0974,  val_acc=0.4585
step=0 loss=1.3738 running loss=1.3536 , time=1.2478 expected time=109.8056
Epoch 54, train_loss=1.4150, train_acc=0.5793 val_loss=2.0666,  val_acc=0.4452
step=0 loss=1.6151 running loss=1.5949 , time=1.2491 expected time=109.9237
Epoch 55, train_loss=1.3978, train_acc=0.5921 val_loss=2.1037,  val_acc=0.4452
step=0 loss=1.1065 running loss=1.0863 , time=1.2515 expected time=110.1287
Epoch 56, train_loss=1.4260, train_acc=0.5629 val_loss=2.0971,  val_acc=0.4618
step=0 loss=1.3517 running loss=1.3315 , time=1.2505 expected time=110.0400
Epoch 57, train_loss=1.3864, train_acc=0.5750 val_loss=2.1436,  val_acc=0.4618
step=0 loss=1.2280 running loss=1.2078 , time=1.2502 expected time=110.0177
Epoch 58, train_loss=1.3966, train_acc=0.5836 val_loss=2.1388,  val_acc=0.4551
step=0 loss=1.4496 running loss=1.4294 , time=1.2458 expected time=109.6309
Epoch 59, train_loss=1.3753, train_acc=0.5736 val_loss=2.1123,  val_acc=0.4684
step=0 loss=1.6463 running loss=1.6261 , time=1.5345 expected time=135.0346
Epoch 60, train_loss=1.4135, train_acc=0.5707 val_loss=2.0645,  val_acc=0.4452
Evaluate on test set
