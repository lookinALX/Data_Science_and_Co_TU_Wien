Echoing to file start
Save config dict to file
Set seed to 1234
Start loading data
End loading data
Generate Datalaoder
Generate Datalaoder end
Start training
step=0 loss=4.2006 running loss=4.1965 , time=3.5539 expected time=312.7390
Epoch 1, train_loss=3.8396, train_acc=0.0400 val_loss=4.2849,  val_acc=0.0233
step=0 loss=3.8818 running loss=3.8730 , time=1.4581 expected time=128.3129
Epoch 2, train_loss=3.7130, train_acc=0.0486 val_loss=3.8364,  val_acc=0.0498
step=0 loss=3.6397 running loss=3.6229 , time=1.2835 expected time=112.9447
Epoch 3, train_loss=3.5306, train_acc=0.0700 val_loss=3.7035,  val_acc=0.0299
step=0 loss=3.3153 running loss=3.2926 , time=1.2664 expected time=111.4442
Epoch 4, train_loss=3.4055, train_acc=0.0764 val_loss=3.3097,  val_acc=0.1229
step=0 loss=2.9395 running loss=2.9119 , time=1.2693 expected time=111.7027
Epoch 5, train_loss=3.3057, train_acc=0.1164 val_loss=3.5857,  val_acc=0.0764
step=0 loss=2.8929 running loss=2.8619 , time=1.2644 expected time=111.2656
Epoch 6, train_loss=3.2168, train_acc=0.1307 val_loss=3.2844,  val_acc=0.1063
step=0 loss=3.1187 running loss=3.0839 , time=1.2615 expected time=111.0091
Epoch 7, train_loss=3.1182, train_acc=0.1321 val_loss=3.2407,  val_acc=0.1096
step=0 loss=3.2209 running loss=3.1832 , time=1.2560 expected time=110.5285
Epoch 8, train_loss=3.0360, train_acc=0.1543 val_loss=3.1595,  val_acc=0.1429
step=0 loss=3.2975 running loss=3.2563 , time=1.2600 expected time=110.8787
Epoch 9, train_loss=2.8845, train_acc=0.2000 val_loss=2.9813,  val_acc=0.1595
step=0 loss=2.9166 running loss=2.8714 , time=1.3233 expected time=116.4492
Epoch 10, train_loss=2.7866, train_acc=0.1986 val_loss=2.8161,  val_acc=0.1894
step=0 loss=2.5700 running loss=2.5204 , time=1.9573 expected time=172.2399
Epoch 11, train_loss=2.6368, train_acc=0.2400 val_loss=3.5717,  val_acc=0.1296
step=0 loss=2.6589 running loss=2.6063 , time=1.9049 expected time=167.6324
Epoch 12, train_loss=2.5547, train_acc=0.2736 val_loss=2.6921,  val_acc=0.2193
step=0 loss=2.6387 running loss=2.5839 , time=1.7672 expected time=155.5104
Epoch 13, train_loss=2.3856, train_acc=0.3100 val_loss=2.7760,  val_acc=0.2259
step=0 loss=2.4213 running loss=2.3640 , time=1.7872 expected time=157.2728
Epoch 14, train_loss=2.3114, train_acc=0.3114 val_loss=2.5107,  val_acc=0.2757
step=0 loss=1.8686 running loss=1.8100 , time=1.7540 expected time=154.3484
Epoch 15, train_loss=2.2321, train_acc=0.3464 val_loss=2.4772,  val_acc=0.2658
step=0 loss=1.8432 running loss=1.7842 , time=1.7876 expected time=157.3052
Epoch 16, train_loss=2.1836, train_acc=0.3700 val_loss=3.1954,  val_acc=0.2558
step=0 loss=2.0405 running loss=1.9791 , time=1.8111 expected time=159.3743
Epoch 17, train_loss=2.1266, train_acc=0.3829 val_loss=2.7193,  val_acc=0.2425
step=0 loss=1.6931 running loss=1.6321 , time=1.8165 expected time=159.8478
Epoch 18, train_loss=2.0422, train_acc=0.4107 val_loss=2.3422,  val_acc=0.3821
step=0 loss=2.0890 running loss=2.0264 , time=1.7843 expected time=157.0154
Epoch 19, train_loss=1.9594, train_acc=0.4321 val_loss=2.3648,  val_acc=0.3555
step=0 loss=1.5815 running loss=1.5185 , time=1.7912 expected time=157.6226
Epoch 20, train_loss=1.8996, train_acc=0.4436 val_loss=2.1812,  val_acc=0.4053
step=0 loss=1.5645 running loss=1.5015 , time=1.8042 expected time=158.7724
Epoch 21, train_loss=1.7755, train_acc=0.4614 val_loss=2.2155,  val_acc=0.3555
step=0 loss=2.0303 running loss=1.9670 , time=1.7995 expected time=158.3603
Epoch 22, train_loss=1.7397, train_acc=0.4907 val_loss=1.8574,  val_acc=0.4651
step=0 loss=1.2621 running loss=1.1985 , time=1.7965 expected time=158.0883
Epoch 23, train_loss=1.6433, train_acc=0.5036 val_loss=2.0552,  val_acc=0.4020
step=0 loss=1.9926 running loss=1.9294 , time=1.7940 expected time=157.8756
Epoch 24, train_loss=1.5731, train_acc=0.5207 val_loss=2.0563,  val_acc=0.3920
step=0 loss=1.9160 running loss=1.8531 , time=1.8156 expected time=159.7748
Epoch 25, train_loss=1.5496, train_acc=0.5329 val_loss=1.8994,  val_acc=0.4551
step=0 loss=1.1045 running loss=1.0419 , time=1.8000 expected time=158.4010
Epoch 26, train_loss=1.4065, train_acc=0.5750 val_loss=1.8112,  val_acc=0.4485
step=0 loss=1.3903 running loss=1.3276 , time=1.7850 expected time=157.0801
Epoch 27, train_loss=1.3965, train_acc=0.5979 val_loss=1.6984,  val_acc=0.4817
step=0 loss=1.4762 running loss=1.4143 , time=1.8190 expected time=160.0740
Epoch 28, train_loss=1.2841, train_acc=0.6179 val_loss=1.8441,  val_acc=0.4917
step=0 loss=1.4606 running loss=1.3987 , time=1.7930 expected time=157.7859
Epoch 29, train_loss=1.2341, train_acc=0.6193 val_loss=1.7151,  val_acc=0.5050
step=0 loss=1.2100 running loss=1.1481 , time=1.7629 expected time=155.1393
Epoch 30, train_loss=1.2438, train_acc=0.6086 val_loss=1.7003,  val_acc=0.5282
step=0 loss=1.1994 running loss=1.1385 , time=1.8089 expected time=159.1796
Epoch 31, train_loss=1.1345, train_acc=0.6650 val_loss=1.6225,  val_acc=0.5050
step=0 loss=0.8918 running loss=0.8308 , time=1.8253 expected time=160.6286
Epoch 32, train_loss=1.1004, train_acc=0.6679 val_loss=1.5049,  val_acc=0.5814
step=0 loss=1.1494 running loss=1.0889 , time=1.8044 expected time=158.7868
Epoch 33, train_loss=0.9894, train_acc=0.6986 val_loss=1.6084,  val_acc=0.5415
step=0 loss=1.5270 running loss=1.4667 , time=1.8351 expected time=161.4925
Epoch 34, train_loss=0.9736, train_acc=0.6993 val_loss=1.5252,  val_acc=0.5515
step=0 loss=1.1282 running loss=1.0681 , time=1.8220 expected time=160.3335
Epoch 35, train_loss=0.8699, train_acc=0.7279 val_loss=1.4793,  val_acc=0.5615
step=0 loss=0.9395 running loss=0.8798 , time=1.7956 expected time=158.0141
Epoch 36, train_loss=0.8036, train_acc=0.7571 val_loss=1.4596,  val_acc=0.5947
step=0 loss=1.2199 running loss=1.1606 , time=1.7995 expected time=158.3596
Epoch 37, train_loss=0.7715, train_acc=0.7707 val_loss=1.4473,  val_acc=0.6013
step=0 loss=0.6738 running loss=0.6148 , time=1.8013 expected time=158.5164
Epoch 38, train_loss=0.7181, train_acc=0.7886 val_loss=1.3993,  val_acc=0.6013
step=0 loss=0.5456 running loss=0.4869 , time=1.7900 expected time=157.5233
Epoch 39, train_loss=0.6587, train_acc=0.8021 val_loss=1.3517,  val_acc=0.6213
step=0 loss=0.8624 running loss=0.8038 , time=1.8110 expected time=159.3658
Epoch 40, train_loss=0.6367, train_acc=0.8000 val_loss=1.3647,  val_acc=0.6179
step=0 loss=0.4637 running loss=0.4053 , time=1.7969 expected time=158.1309
Epoch 41, train_loss=0.5801, train_acc=0.8336 val_loss=1.3367,  val_acc=0.6478
step=0 loss=0.4881 running loss=0.4300 , time=1.7969 expected time=158.1277
Epoch 42, train_loss=0.5553, train_acc=0.8407 val_loss=1.3643,  val_acc=0.6013
step=0 loss=0.9158 running loss=0.8578 , time=1.8199 expected time=160.1545
Epoch 43, train_loss=0.5217, train_acc=0.8529 val_loss=1.3445,  val_acc=0.6346
step=0 loss=0.6361 running loss=0.5781 , time=1.7810 expected time=156.7257
Epoch 44, train_loss=0.4786, train_acc=0.8714 val_loss=1.3112,  val_acc=0.6412
step=0 loss=0.4780 running loss=0.4201 , time=1.7917 expected time=157.6661
Epoch 45, train_loss=0.4805, train_acc=0.8700 val_loss=1.3489,  val_acc=0.6246
step=0 loss=0.6632 running loss=0.6054 , time=1.8244 expected time=160.5487
Epoch 46, train_loss=0.4571, train_acc=0.8679 val_loss=1.3285,  val_acc=0.6412
step=0 loss=0.2772 running loss=0.2195 , time=1.8245 expected time=160.5556
Epoch 47, train_loss=0.4419, train_acc=0.8893 val_loss=1.3140,  val_acc=0.6213
step=0 loss=0.4723 running loss=0.4145 , time=1.8159 expected time=159.7965
Epoch 48, train_loss=0.4307, train_acc=0.8771 val_loss=1.3450,  val_acc=0.6246
step=0 loss=0.4077 running loss=0.3500 , time=1.7801 expected time=156.6481
Epoch 49, train_loss=0.4301, train_acc=0.8871 val_loss=1.3248,  val_acc=0.6379
step=0 loss=0.4921 running loss=0.4343 , time=1.8122 expected time=159.4711
Epoch 50, train_loss=0.4233, train_acc=0.8793 val_loss=1.3389,  val_acc=0.6379
Evaluate on test set
