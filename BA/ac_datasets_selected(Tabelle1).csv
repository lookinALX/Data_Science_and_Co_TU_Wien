Dataset;Number of citations (Google Scholar);Number of Papers (Papers with code since 2020);Number of Evaluations (Papers with code API);Music/Speech/Sounds;Link;Paper Link;Model in Paper (Paper Link if Link Model Paper == null);Model in Paper Input Data;Score or best score in Paper;Metrics in Paper;Year;Author;Original Usecase;Accessable;Downloadable;Download Comment;Category Source;Size (Hours);Contents based on;Source;Language;Number of Benchmarks (Audio Classification or Recognition Papers with Code different models);Best Scoure;Best Model related to scoure;Best Model Input Data;Metrics related to scoure;Link Model Paper;Comment; Number of Classes;Duration of Each Clip (Up to sec);Number of Audio Clips
UrbanSound8K;1653,00;100,00;4,00;Sounds;https://urbansounddataset.weebly.com/urbansound8k.html;https://www.justinsalamon.com/uploads/4/3/9/4/4394963/salamon_urbansound_acmmm14.pdf;SVM;Mel-Frequency Cepstral Coefficients (MFCC);70,000;Accuracy;2014;Freesound.org;Audio classification;yes;Easy;Direct download;Environment recordings;27607;audio clips;Freesound.org;n/a;4,00;98,05;FACE;Mel-Frequency Cepstral Coefficients (MFCC);Accuracy;https://arxiv.org/pdf/2303.03666v1;n/a;10;4;8732
ESC-50;1872,00;302,00;540,00;Sounds;https://github.com/karolpiczak/ESC-50;https://dl.acm.org/doi/10.1145/2733373.2806390;n/a;n/a;n/a;n/a;2015;n/a;Audio classification;yes;Easy;Direct download;Environment recordings;28157;audio clips;Freesound.org;n/a;50,00;99,10;OmniVec2;Spectrogram;Accuracy;https://paperswithcode.com/paper/omnivec2-a-novel-transformer-based-network;n/a;50;5;2000
FSD50K;524,00;139,00;10,00;Sounds;https://zenodo.org/records/4060432;https://dl.acm.org/doi/10.1109/TASLP.2021.3133208;n/a;n/a;n/a;n/a;2020;n/a;Audio classification;yes;Easy;Direct download;User-contributed sounds;145;short video clips;"Freesound.org; AudioSet";English;9,00;69,70;ONE-PEACE;Raw Audio;mAP (mean Average Precision);https://arxiv.org/pdf/2305.11172v1;n/a;200;n/a;50000
SHD (Spiking Heidelberg Digits);209,00;16,00;11,00;Speech;https://zenkelab.org/resources/spiking-heidelberg-datasets-shd/;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9311226;CNN;Spectrogram;92,400;Accuracy;2022;Zenke Lab;Audio classification;yes;Easy;Direct download;Speech recordings;n/a;audio clips;Recoding;English;11,00;95,90;Event-SSM;Raw Audio;Accuracy;https://arxiv.org/pdf/2404.18508v3;n/a;10;1;10000
TAU2020;132,00;0,00;0,00;Sounds;https://zenodo.org/records/3670167;https://arxiv.org/abs/2006.01919;CNN (SELD);Spectrogram;n/a;n/a;2020;n/a;Audio classification;yes;Easy;Direct download;Mixed sources;64;audio clips;Public area recordings;n/a;n/a;n/a;n/a;n/a;n/a;n/a;n/a;14;10;22000
Kinetics-700;179,00;89,00;38,00;Sounds;https://github.com/cvdfoundation/kinetics-dataset;https://arxiv.org/abs/2010.10864;ResNet50;Spectrogram;80,000;Accuracy;2020;Google;Audio classification;yes;Easy;Direct download;YouTube videos;1805;short video clips;Youtube;n/a;36,00;85,90;InternVideo2-6B;;Top1 Accuracy;https://arxiv.org/pdf/2403.15377v4;Only Audio Task;700;10;700000
EmoDB Dataset (Berlin Database of Emotional Speech);3072,00;6,00;0,00;Speech;https://audeering.github.io/datasets/datasets/emodb.html;https://www.researchgate.net/publication/221491017_A_database_of_German_emotional_speech;n/a;n/a;n/a;n/a;2005;"T-Systems; University";Audio classification;yes;Easy;Direct download;Speech recordings;0,41;audio clips;Recoding;German;1,00;90,20;VQ-MAE-S-12 (Frame) ;Spectrogram;"	Accuracy";https://arxiv.org/pdf/2304.11117v1;n/a;7;5;535
MINDS-14;29,00;0,00;0,00;Speech;https://huggingface.co/datasets/PolyAI/minds14/tree/main/data;https://arxiv.org/pdf/2104.08524;Google ASR;Raw Audio;93,300;Accuracy;2021;PolyAI;Audio classification;yes;Easy;Direct download;Speech recordings;27;audio clips;Crowdsourcing;Multilingual;n/a;58,00;DP-DyLoRA;Spectrogram;"	Accuracy";https://arxiv.org/pdf/2405.06368;SPEECH RECOGNITION. paper found on Scholar;14;1;14000
RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song);2154,00;25,00;0,00;Speech;https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio;https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0196391;n/a;n/a;n/a;n/a;2018;University;Audio classification;yes;Easy;Direct download;Singing recordings;45797;short video clips;Recoding;English;2,00;75,40;ASM-RH-A;Spectrogram;Top1 Accuracy;https://arxiv.org/pdf/2402.18007v2;Audio Classification;8;5;2480
COUGHVID;334,00;27,00;0,00;Sounds;https://c4science.ch/diffusion/10770/;https://www.nature.com/articles/s41597-021-00937-4;eXtreme Gradient Boosting (XGB)1;n/a;86,700;Accuracy;2021;n/a;Audio classification;yes;Easy;Direct download;Medical recordings;35;audio clips;Crowdsourcing;n/a;n/a;0,70;OPERA-CT;Spectrogram;MRR;https://arxiv.org/pdf/2406.16148v3;n/a;2;4;10000
Cat Meow;0,00;0,00;0,00;Sounds;https://www.kaggle.com/datasets/andrewmvd/cat-meow-classification;https://d1wqtxts1xzle7.cloudfront.net/94765084/Ludovico2021_Chapter_CatMeowsAPublicly-AvailableDat-libre.pdf?1669278110=&response-content-disposition=inline%3B+filename%3DCatMeows_A_Publicly_Available_Dataset_of.pdf&Expires=1734885889&Signature=gIFKEtCtihOopajb0Hdx0F2Hx4Z-gZKXJ1xuU-~mT3Lfmm2BQsTUW2qf1BR~OVgo7ScrWIibg0mR3IE~5Alpz5Tictf0CM~mVHdtzeYVkNyHoq82PB5B96puKLTuFhNPC5T8P-g7jyCzzMPzYzu0Xp98zUEgr~QWW31Fkva4kQO9SfOeys6QCqAxNp~EULwXQme3H5SQQVcOqCyX0Vvp706h1149oHgbQ-qr95APjzaQeHjUUYtKihYMrXJdQoXlWDujK0Geordg7jvl8uDklUHnrxt5hLQLWLJzz00lJbxYL5WBwc-w9bQaer4mVBNNiBebn0EeOFnqpxroQu9HrA__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA;RandomForestClassifier;n/a;0,730;F1;2021;University;Audio classification;yes;Easy;Direct download;Animal recordings;0,30;audio clips;Recoding;n/a;n/a;n/a;n/a;n/a;n/a;https://www.kaggle.com/code/kanyaratp29/csc287-cat-sound-classification#Evaluation;n/a;3;2;440
CochlScene;22,00;4,00;2,00;Sounds;https://zenodo.org/records/7080122;https://arxiv.org/abs/2211.02289;n/a;n/a;n/a;n/a;2022;n/a;Audio classification;yes;Easy;Direct download;Environment recordings;211,50;audio clips;Crowdsourcing;n/a;2,00;83,00;NVIDIA Audio Flamingo;n/a;Accuracy;https://arxiv.org/pdf/2402.01831v3;n/a;10;10;5000
Free Spoken Digit Dataset (FSDD);50,00;3,00;0,00;Speech;https://github.com/Jakobovski/free-spoken-digit-dataset?tab=readme-ov-file;https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10206077;Deep Convolution Neural Network (DCNN);Spectrogram;97,6;Accuracy;2018;MNIST;Audio classification;yes;Easy;Direct download;Speech recordings;0,83;audio clips;Crowdsourcing;English;n/a;n/a;n/a;n/a;n/a;n/a;n/a;10;1;2000
AudioMNIST;43,00;3,00;0,00;Speech;https://github.com/soerenab/AudioMNIST;https://arxiv.org/pdf/1807.03418;AlexNet (spectrogram);Spectrogram;95,820;Accuracy;2018;MNIST;Audio classification;yes;Easy;Direct download;Speech recordings;8,33;audio clips;Recoding;English;n/a;n/a;n/a;n/a;n/a;n/a;n/a;10;1;200000
SpokeN-100;1,00;0,00;0,00;Speech;https://zenodo.org/records/10810044;https://arxiv.org/html/2403.09753v1;EfficientNet-B0 CNN;Spectrogram;84,800;Accuracy;2024;University;Audio classification;yes;Easy;Direct download;AI-generated synthetic speech;3,56;audio clips;Artificially generated (text promts);Multilingual;n/a;n/a;n/a;n/a;n/a;n/a;n/a;100;2;100000
